{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalKaggle",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cWVCm-xeAsh",
        "colab_type": "code",
        "outputId": "149e0266-b311-4183-d529-a37c85b125df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeZ2_iwvmcHY",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IUAZbtIC0Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd  \n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import sys\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "# from catboost import CatBoostRegressor\n",
        "# from category_encoders import TargetEncoder\n",
        "\n",
        "import lightgbm\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "\n",
        "## importing Dataset\n",
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/tcd-ml-1920-group-income-train.csv', dtype={'Year of Record': object, 'Housing Situation': object, 'Work Experience in Current Job [years]': object})\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/tcd-ml-1920-group-income-test.csv', dtype={'Year of Record': object, 'Housing Situation': object, 'Work Experience in Current Job [years]': object})\n",
        "dataset = pd.concat([train,test],ignore_index=True)\n",
        "\n",
        "def preprocessing(dataset):\n",
        "\n",
        "    # Converting Dataset to numeric type\n",
        "    dataset['Year of Record'] = pd.to_numeric(dataset['Year of Record'])\n",
        "    dataset['Total Yearly Income [EUR]'] = pd.to_numeric(dataset['Total Yearly Income [EUR]'])\n",
        "    \n",
        "    # Year of Record\n",
        "    dataset['Year of Record'] = dataset['Year of Record'].fillna(1940)\n",
        "\n",
        "    # Housing\n",
        "    dataset['Housing Situation'] = dataset['Housing Situation'].replace('0', 'Unknown House')\n",
        "    dataset['Housing Situation'] = dataset['Housing Situation'].replace('nA', 'Unknown House')\n",
        "    dataset['Housing Situation'] = dataset['Housing Situation'].fillna('Unknown House')\n",
        "\n",
        "    # Crime Level\n",
        "    dataset['Crime Level in the City of Employement'] = dataset['Crime Level in the City of Employement'].fillna(0)\n",
        "\n",
        "    # Work exp\n",
        "    dataset['Work Experience in Current Job [years]'] = dataset['Work Experience in Current Job [years]'].fillna(0)\n",
        "    dataset[\"Work Experience in Current Job [years]\"] = dataset[\"Work Experience in Current Job [years]\"].replace('#NUM!',0)\n",
        "    dataset['Work Experience in Current Job [years]'] = pd.to_numeric(dataset['Work Experience in Current Job [years]'])\n",
        "\n",
        "\n",
        "    # Satisfaction\n",
        "    dataset[\"Satisfation with employer\"] = dataset[\"Satisfation with employer\"].fillna(\"Unknown Satisfaction\")\n",
        "\n",
        "\n",
        "    # Gender\n",
        "    dataset['Gender'] = dataset['Gender'].replace({'f':'female', '0':'unknown'})\n",
        "    dataset['Gender'] = dataset['Gender'].fillna('unknown')\n",
        "\n",
        "    # Age\n",
        "    dataset['Age'] = dataset['Age'].fillna(0)\n",
        "\n",
        "    # Country\n",
        "    dataset['Country'] = dataset['Country'].replace('0', 'Unknown Country')\n",
        "    dataset['Country'] = dataset['Country'].replace('#N/A', 'Unknown Country')\n",
        "\n",
        "\n",
        "    # Size city\n",
        "    dataset['Size of City'] = dataset['Size of City'].fillna(0)\n",
        "\n",
        "    # Profession\n",
        "    dataset['Profession'] = dataset['Profession'].replace('0', 'Unknown Profession')\n",
        "\n",
        "    # Degree\n",
        "    dataset['University Degree'] = dataset['University Degree'].replace('0', 'Unknown University').fillna('Unknown University')\n",
        "\n",
        "    # Glasses\n",
        "    dataset['Wears Glasses'] = dataset['Wears Glasses']+1\n",
        "\n",
        "    # Hair\n",
        "    dataset['Hair Color'] = dataset['Hair Color'].replace({'0':'unknown'})\n",
        "    dataset['Hair Color'] = dataset['Hair Color'].fillna('unknown')\n",
        "\n",
        "    # Height was changed using gaussian distribution height feature\n",
        "    '''\n",
        "    dataset.loc[(dataset['Body Height [cm]'] > 145) & (dataset['Body Height [cm]'] < 200), 'Average Height'] = 1\n",
        "    dataset.loc[(dataset['Body Height [cm]'] <= 145) | (dataset['Body Height [cm]'] >= 200), 'Average Height'] = 0\n",
        "    '''\n",
        "\n",
        "    # Add salary\n",
        "    dataset['Yearly Income in addition to Salary (e.g. Rental Income)'] = dataset['Yearly Income in addition to Salary (e.g. Rental Income)'].replace(' EUR', '', regex=True).astype('float')\n",
        "    \n",
        "    # dropping some columns\n",
        "    # dataset = dataset.drop(columns=['University Degree'])\n",
        "    # dataset = dataset.drop(columns=['Wears Glasses'])\n",
        "    # dataset = dataset.drop(columns=['Year of Record'])\n",
        "    # dataset = dataset.drop(columns=['Gender'])\n",
        "    # dataset = dataset.drop(columns=['Crime Level in the City of Employement'])\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def addCountFeatures(dataset,features):\n",
        "    # print(dataset.columns)\n",
        "    for feature in features:\n",
        "      new_feature = \"no.of_\"+str(feature)\n",
        "      countFeature = dataset[feature].value_counts(dropna=False,normalize=False).to_dict()\n",
        "      dataset[new_feature] = dataset[feature].map(countFeature)\n",
        "      dataset[new_feature] = dataset[new_feature].astype('float32')\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def HandlingCategorical(dataset):\n",
        "    for col in dataset.columns:\n",
        "      col_type = dataset[col].dtype\n",
        "      # print(\"type\",dataset[col].dtype)\n",
        "      if col_type.name == 'category':\n",
        "        print(\"Handling\",col)\n",
        "        encoder = LabelEncoder()\n",
        "        dataset[col] = encoder.fit_transform(dataset[col].astype(str))\n",
        "    \n",
        "    return dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYSoM0uKQ1Ur",
        "colab_type": "code",
        "outputId": "b526c680-ca88-4af1-db7d-0450d30bd1d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "source": [
        "## preprocessing\n",
        "dataset = preprocessing(dataset)\n",
        "\n",
        "## seperation of income column\n",
        "y = train['Total Yearly Income [EUR]']\n",
        "dataset.drop(['Instance', 'Total Yearly Income [EUR]'], inplace=True, axis=1)\n",
        "\n",
        "## adding count of each feature\n",
        "dataset = addCountFeatures(dataset,dataset.columns)\n",
        "print(dataset.columns)\n",
        "\n",
        "## converting to categorical data types\n",
        "for c in dataset.columns:\n",
        "  col_type = dataset[c].dtype\n",
        "  if col_type == 'object' or col_type.name == 'category':\n",
        "      dataset[c] = dataset[c].astype('category')\n",
        "\n",
        "## Categorical Encoding\n",
        "dataset = HandlingCategorical(dataset)\n",
        "\n",
        "## splitting the dataset into Train and test again\n",
        "train = dataset.iloc[:len(train),:]\n",
        "test = dataset.iloc[len(train):,:]\n",
        "\n",
        "## splitting dataset in training and validation sets\n",
        "x = train\n",
        "# y = np.log(y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=619)\n",
        "print(\"\\n\\n   Dataset to be trained \\n\",x.dtypes)\n",
        "\n",
        "# Create the LightGBM data containers\n",
        "train_data = lightgbm.Dataset(x_train, label=y_train)\n",
        "test_data = lightgbm.Dataset(x_test, label=y_test)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Year of Record', 'Housing Situation',\n",
            "       'Crime Level in the City of Employement',\n",
            "       'Work Experience in Current Job [years]', 'Satisfation with employer',\n",
            "       'Gender', 'Age', 'Country', 'Size of City', 'Profession',\n",
            "       'University Degree', 'Wears Glasses', 'Hair Color', 'Body Height [cm]',\n",
            "       'Yearly Income in addition to Salary (e.g. Rental Income)',\n",
            "       'no.of_Year of Record', 'no.of_Housing Situation',\n",
            "       'no.of_Crime Level in the City of Employement',\n",
            "       'no.of_Work Experience in Current Job [years]',\n",
            "       'no.of_Satisfation with employer', 'no.of_Gender', 'no.of_Age',\n",
            "       'no.of_Country', 'no.of_Size of City', 'no.of_Profession',\n",
            "       'no.of_University Degree', 'no.of_Wears Glasses', 'no.of_Hair Color',\n",
            "       'no.of_Body Height [cm]',\n",
            "       'no.of_Yearly Income in addition to Salary (e.g. Rental Income)'],\n",
            "      dtype='object')\n",
            "Handling Housing Situation\n",
            "Handling Satisfation with employer\n",
            "Handling Gender\n",
            "Handling Country\n",
            "Handling Profession\n",
            "Handling University Degree\n",
            "Handling Hair Color\n",
            "\n",
            "\n",
            "   Dataset to be trained \n",
            " Year of Record                                                    float64\n",
            "Housing Situation                                                   int64\n",
            "Crime Level in the City of Employement                              int64\n",
            "Work Experience in Current Job [years]                            float64\n",
            "Satisfation with employer                                           int64\n",
            "Gender                                                              int64\n",
            "Age                                                                 int64\n",
            "Country                                                             int64\n",
            "Size of City                                                        int64\n",
            "Profession                                                          int64\n",
            "University Degree                                                   int64\n",
            "Wears Glasses                                                       int64\n",
            "Hair Color                                                          int64\n",
            "Body Height [cm]                                                    int64\n",
            "Yearly Income in addition to Salary (e.g. Rental Income)          float64\n",
            "no.of_Year of Record                                              float32\n",
            "no.of_Housing Situation                                           float32\n",
            "no.of_Crime Level in the City of Employement                      float32\n",
            "no.of_Work Experience in Current Job [years]                      float32\n",
            "no.of_Satisfation with employer                                   float32\n",
            "no.of_Gender                                                      float32\n",
            "no.of_Age                                                         float32\n",
            "no.of_Country                                                     float32\n",
            "no.of_Size of City                                                float32\n",
            "no.of_Profession                                                  float32\n",
            "no.of_University Degree                                           float32\n",
            "no.of_Wears Glasses                                               float32\n",
            "no.of_Hair Color                                                  float32\n",
            "no.of_Body Height [cm]                                            float32\n",
            "no.of_Yearly Income in addition to Salary (e.g. Rental Income)    float32\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlb7zNiBuAIa",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fjyRC02K-sU",
        "colab_type": "code",
        "outputId": "1ce526ea-18d7-4ed4-9f08-115869a291c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "parameters = {\n",
        "    'objective': 'tweedie',\n",
        "    'max_depth':30,\n",
        "    'learning_rate': 0.1,\n",
        "    'metric': 'mae',\n",
        "    'feature_fraction': 0.8,\n",
        "    'boosting': 'gbdt',\n",
        "    'bagging_freq': 20,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "model = lightgbm.train(parameters,\n",
        "                       train_data,\n",
        "                       valid_sets=[train_data,test_data],\n",
        "                       verbose_eval=100,\n",
        "                       num_boost_round=10000,\n",
        "                       early_stopping_rounds=500)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\ttraining's l1: 9986.23\tvalid_1's l1: 10047.6\n",
            "[200]\ttraining's l1: 9134.61\tvalid_1's l1: 9247.36\n",
            "[300]\ttraining's l1: 8866.93\tvalid_1's l1: 9022.21\n",
            "[400]\ttraining's l1: 8668.36\tvalid_1's l1: 8868.04\n",
            "[500]\ttraining's l1: 8541.72\tvalid_1's l1: 8788.07\n",
            "[600]\ttraining's l1: 8422.34\tvalid_1's l1: 8709.7\n",
            "[700]\ttraining's l1: 8312.91\tvalid_1's l1: 8648.97\n",
            "[800]\ttraining's l1: 8223.54\tvalid_1's l1: 8605.74\n",
            "[900]\ttraining's l1: 8136.57\tvalid_1's l1: 8563.31\n",
            "[1000]\ttraining's l1: 8056.92\tvalid_1's l1: 8526.17\n",
            "[1100]\ttraining's l1: 7975.44\tvalid_1's l1: 8492.8\n",
            "[1200]\ttraining's l1: 7905.52\tvalid_1's l1: 8469.42\n",
            "[1300]\ttraining's l1: 7837.83\tvalid_1's l1: 8449.59\n",
            "[1400]\ttraining's l1: 7775.79\tvalid_1's l1: 8431.12\n",
            "[1500]\ttraining's l1: 7715.57\tvalid_1's l1: 8415.24\n",
            "[1600]\ttraining's l1: 7655.6\tvalid_1's l1: 8399.15\n",
            "[1700]\ttraining's l1: 7605.53\tvalid_1's l1: 8390.2\n",
            "[1800]\ttraining's l1: 7552.29\tvalid_1's l1: 8379.46\n",
            "[1900]\ttraining's l1: 7503.31\tvalid_1's l1: 8371.47\n",
            "[2000]\ttraining's l1: 7453.8\tvalid_1's l1: 8364.22\n",
            "[2100]\ttraining's l1: 7410.12\tvalid_1's l1: 8359.69\n",
            "[2200]\ttraining's l1: 7367.37\tvalid_1's l1: 8348.17\n",
            "[2300]\ttraining's l1: 7320.65\tvalid_1's l1: 8340.48\n",
            "[2400]\ttraining's l1: 7274.56\tvalid_1's l1: 8334.69\n",
            "[2500]\ttraining's l1: 7230.9\tvalid_1's l1: 8328.18\n",
            "[2600]\ttraining's l1: 7185.24\tvalid_1's l1: 8322.93\n",
            "[2700]\ttraining's l1: 7143.29\tvalid_1's l1: 8318.41\n",
            "[2800]\ttraining's l1: 7102.34\tvalid_1's l1: 8314.9\n",
            "[2900]\ttraining's l1: 7062.48\tvalid_1's l1: 8312.47\n",
            "[3000]\ttraining's l1: 7019.62\tvalid_1's l1: 8305.92\n",
            "[3100]\ttraining's l1: 6981.13\tvalid_1's l1: 8303.57\n",
            "[3200]\ttraining's l1: 6941.12\tvalid_1's l1: 8300.77\n",
            "[3300]\ttraining's l1: 6902.92\tvalid_1's l1: 8296.44\n",
            "[3400]\ttraining's l1: 6864.95\tvalid_1's l1: 8294.63\n",
            "[3500]\ttraining's l1: 6832.31\tvalid_1's l1: 8291.49\n",
            "[3600]\ttraining's l1: 6795.43\tvalid_1's l1: 8288.67\n",
            "[3700]\ttraining's l1: 6754.49\tvalid_1's l1: 8284.13\n",
            "[3800]\ttraining's l1: 6718.67\tvalid_1's l1: 8279.61\n",
            "[3900]\ttraining's l1: 6685.25\tvalid_1's l1: 8273.95\n",
            "[4000]\ttraining's l1: 6651.08\tvalid_1's l1: 8273.15\n",
            "[4100]\ttraining's l1: 6617.24\tvalid_1's l1: 8271.83\n",
            "[4200]\ttraining's l1: 6585.07\tvalid_1's l1: 8267.89\n",
            "[4300]\ttraining's l1: 6554.19\tvalid_1's l1: 8266.96\n",
            "[4400]\ttraining's l1: 6525.29\tvalid_1's l1: 8265.18\n",
            "[4500]\ttraining's l1: 6496.79\tvalid_1's l1: 8264.08\n",
            "[4600]\ttraining's l1: 6462.04\tvalid_1's l1: 8260.7\n",
            "[4700]\ttraining's l1: 6433.19\tvalid_1's l1: 8259.04\n",
            "[4800]\ttraining's l1: 6404.31\tvalid_1's l1: 8256.11\n",
            "[4900]\ttraining's l1: 6374.42\tvalid_1's l1: 8254.85\n",
            "[5000]\ttraining's l1: 6348.86\tvalid_1's l1: 8253.79\n",
            "[5100]\ttraining's l1: 6318.82\tvalid_1's l1: 8253.98\n",
            "[5200]\ttraining's l1: 6293.48\tvalid_1's l1: 8253.2\n",
            "[5300]\ttraining's l1: 6267.77\tvalid_1's l1: 8251.65\n",
            "[5400]\ttraining's l1: 6241.37\tvalid_1's l1: 8251.1\n",
            "[5500]\ttraining's l1: 6211.76\tvalid_1's l1: 8249.86\n",
            "[5600]\ttraining's l1: 6181\tvalid_1's l1: 8249.06\n",
            "[5700]\ttraining's l1: 6152.73\tvalid_1's l1: 8250.98\n",
            "[5800]\ttraining's l1: 6125.38\tvalid_1's l1: 8250.39\n",
            "[5900]\ttraining's l1: 6099.66\tvalid_1's l1: 8248.15\n",
            "[6000]\ttraining's l1: 6071.91\tvalid_1's l1: 8247.6\n",
            "[6100]\ttraining's l1: 6047.11\tvalid_1's l1: 8247.06\n",
            "[6200]\ttraining's l1: 6021.64\tvalid_1's l1: 8245.48\n",
            "[6300]\ttraining's l1: 5996.57\tvalid_1's l1: 8244.97\n",
            "[6400]\ttraining's l1: 5974.43\tvalid_1's l1: 8245.7\n",
            "[6500]\ttraining's l1: 5950.04\tvalid_1's l1: 8244.81\n",
            "[6600]\ttraining's l1: 5928.95\tvalid_1's l1: 8244.21\n",
            "[6700]\ttraining's l1: 5904.45\tvalid_1's l1: 8244.07\n",
            "[6800]\ttraining's l1: 5879.14\tvalid_1's l1: 8242.56\n",
            "[6900]\ttraining's l1: 5852.7\tvalid_1's l1: 8241.75\n",
            "[7000]\ttraining's l1: 5827.17\tvalid_1's l1: 8241.44\n",
            "[7100]\ttraining's l1: 5799.32\tvalid_1's l1: 8240.15\n",
            "[7200]\ttraining's l1: 5778.49\tvalid_1's l1: 8239.4\n",
            "[7300]\ttraining's l1: 5751.84\tvalid_1's l1: 8237.68\n",
            "[7400]\ttraining's l1: 5729.1\tvalid_1's l1: 8236.63\n",
            "[7500]\ttraining's l1: 5707.11\tvalid_1's l1: 8235.6\n",
            "[7600]\ttraining's l1: 5685.05\tvalid_1's l1: 8235.91\n",
            "[7700]\ttraining's l1: 5664.01\tvalid_1's l1: 8235.6\n",
            "[7800]\ttraining's l1: 5644.65\tvalid_1's l1: 8234.25\n",
            "[7900]\ttraining's l1: 5622.2\tvalid_1's l1: 8233.26\n",
            "[8000]\ttraining's l1: 5598.73\tvalid_1's l1: 8231.92\n",
            "[8100]\ttraining's l1: 5574.05\tvalid_1's l1: 8231.81\n",
            "[8200]\ttraining's l1: 5551.15\tvalid_1's l1: 8232.42\n",
            "[8300]\ttraining's l1: 5529.73\tvalid_1's l1: 8230.96\n",
            "[8400]\ttraining's l1: 5508.87\tvalid_1's l1: 8230.72\n",
            "[8500]\ttraining's l1: 5488.72\tvalid_1's l1: 8230.67\n",
            "[8600]\ttraining's l1: 5469.13\tvalid_1's l1: 8228.93\n",
            "[8700]\ttraining's l1: 5448.1\tvalid_1's l1: 8228.72\n",
            "[8800]\ttraining's l1: 5427.88\tvalid_1's l1: 8229.46\n",
            "[8900]\ttraining's l1: 5407.51\tvalid_1's l1: 8228.83\n",
            "[9000]\ttraining's l1: 5388.46\tvalid_1's l1: 8227.38\n",
            "[9100]\ttraining's l1: 5368.39\tvalid_1's l1: 8227.07\n",
            "[9200]\ttraining's l1: 5346.74\tvalid_1's l1: 8227.33\n",
            "[9300]\ttraining's l1: 5325.65\tvalid_1's l1: 8226.59\n",
            "[9400]\ttraining's l1: 5303.85\tvalid_1's l1: 8226.52\n",
            "[9500]\ttraining's l1: 5283.11\tvalid_1's l1: 8226.67\n",
            "[9600]\ttraining's l1: 5264.48\tvalid_1's l1: 8226.89\n",
            "[9700]\ttraining's l1: 5245.62\tvalid_1's l1: 8226.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LvYrgbJmkkh",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5fbsuMPNM-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y = model.predict(test)\n",
        "print(y)\n",
        "sub = pd.DataFrame(y)\n",
        "\n",
        "index = (np.arange(1,len(sub),1).astype(np.int32))\n",
        "# print(testDataset_prediction.index)\n",
        "sub.index += 1\n",
        "print(sub.index)\n",
        "\n",
        "## making csv\n",
        "sub.to_csv(\"/content/drive/My Drive/Colab Notebooks/lgbmCountGBDtABnormal3.csv\",header=['Total Yearly Income [EUR]'],index_label='Instance')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}